
# Tensorflow Attention
Dynamic Attention model implementation using Tensorflow along with some examples.

### Papers for LSTM:
- LONG SHORT-TERM MEMORY
http://www.bioinf.jku.at/publications/older/2604.pdf
- Blog:
http://colah.github.io/posts/2015-08-Understanding-LSTMs/

### Papers for attention:
- Pointer Networks:
https://arxiv.org/abs/1506.03134
- Get To The Point: Summarization with Pointer-Generator Networks:
https://arxiv.org/abs/1704.04368
- Effective Approaches to Attention-based Neural Machine Translation:
https://arxiv.org/abs/1508.04025

### Papers for sentiment classification:
- Attention-based LSTM for Aspect-level Sentiment Classification:  based on semEval dataset
https://aclweb.org/anthology/D16-1058
- Recurrent Attention Network on Memory for Aspect Sentiment Analysis:
http://www.cs.cmu.edu/~lbing/pub/emnlp17_aspect_sentiment.pdf

### Papers for summarization:
- Get To The Point: Summarization with Pointer-Generator Networks:
https://arxiv.org/abs/1704.04368
